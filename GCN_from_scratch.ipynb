{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49W-WghZVMeG",
        "outputId": "aa35a52b-6e58-49ee-f690-b444437f2eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Collecting dgl==1.0.1+cu117\n",
            "  Downloading https://data.dgl.ai/wheels/cu117/dgl-1.0.1%2Bcu117-cp310-cp310-manylinux1_x86_64.whl (266.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.0.1+cu117) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.0.1+cu117) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.0.1+cu117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.0.1+cu117) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.0.1+cu117) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "  Attempting uninstall: dgl\n",
            "    Found existing installation: dgl 1.1.2\n",
            "    Uninstalling dgl-1.1.2:\n",
            "      Successfully uninstalled dgl-1.1.2\n",
            "Successfully installed dgl-1.0.1+cu117\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl==1.0.1+cu117 -f https://data.dgl.ai/wheels/cu117/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, time\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6kk4shTVOmn",
        "outputId": "8cd86472-9435-4f96-e46a-8fc70add4050"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_msg = fn.copy_u(u='h', out='msg')\n",
        "gcn_reduce = fn.sum(msg='msg', out = 'h')\n",
        "class GCNlayer(nn.Module):\n",
        "  def __init__(self, in_feats, out_feats):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(in_feats, out_feats)\n",
        "\n",
        "  def forward(self, g, features):\n",
        "    with g.local_scope():\n",
        "      g.ndata['h'] = features\n",
        "      g.update_all(gcn_msg, gcn_reduce)\n",
        "      h = g.ndata['h']\n",
        "      return self.linear(h)"
      ],
      "metadata": {
        "id": "bFNQux1vW6P9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import CoraGraphDataset\n",
        "dataset = CoraGraphDataset()\n",
        "g = dataset[0].to('cuda')\n",
        "num_nodes, num_feats = g.ndata['feat'].shape\n",
        "num_classes = len(torch.unique(g.ndata['label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMpdYigKa82s",
        "outputId": "c4b52e7f-8fef-4358-8c00-da9ef75c1cfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, num_feats, hidden_dim, num_classes):\n",
        "    super().__init__()\n",
        "    self.gcn1 = GCNlayer(num_feats, hidden_dim)\n",
        "    self.gcn2 = GCNlayer(hidden_dim, num_classes)\n",
        "\n",
        "  def forward(self, g, x):\n",
        "    x = F.relu(self.gcn1(g, x))\n",
        "    x = self.gcn2(g, x)\n",
        "    return x\n",
        "\n",
        "model = GCN(num_feats=num_feats, hidden_dim=16, num_classes=num_classes).to('cuda')\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeOkaE4VK5nW",
        "outputId": "dcbfda7f-db92-4815-fcc7-adc2b82a3509"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (gcn1): GCNlayer(\n",
            "    (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  )\n",
            "  (gcn2): GCNlayer(\n",
            "    (linear): Linear(in_features=16, out_features=7, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs, optimizer):\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "    g.add_edges(g.nodes(), g.nodes()) # Add edges between each node and itself to preserve old node representations\n",
        "\n",
        "    best_train_acc = best_val_acc = 0\n",
        "    for e in range(num_epochs):\n",
        "      t0 = time.time()\n",
        "      logits = model(g, features)\n",
        "      preds = logits.argmax(1)\n",
        "      loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "      train_preds, val_preds = preds[train_mask], preds[val_mask]\n",
        "      train_acc, val_acc = (preds[train_mask] == labels[train_mask]).float().mean(), (preds[val_mask] == labels[val_mask]).float().mean()\n",
        "      best_train_acc = train_acc if train_acc > best_train_acc else best_train_acc\n",
        "      best_val_acc = val_acc if val_acc > best_val_acc else best_val_acc\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      t_p_e = time.time() - t0\n",
        "\n",
        "      if e % 5 == 0:\n",
        "        print(f'Finished training of epoch {e}/{num_epochs} in {t_p_e:.3f}s,\\n \\\n",
        "        CE loss is {loss:3f}, training accuracy is {train_acc:.3f}, validation accuracy is {val_acc:.3f}\\n \\\n",
        "        best train accuracy is {best_train_acc:.3f}, best validation accuracy is {best_val_acc:.3f}.')\n",
        "\n",
        "model = GCN(num_feats=num_feats, hidden_dim=16, num_classes=num_classes).to('cuda')\n",
        "num_epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train(model=model, num_epochs=num_epochs, optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pewlciFsYQvo",
        "outputId": "9e5b3b97-349a-4701-8290-5ba45b145d23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training of epoch 0/100 in 4.228s,\n",
            "         CE loss is 1.955010, training accuracy is 0.093, validation accuracy is 0.066\n",
            "         best train accuracy is 0.093, best validation accuracy is 0.066.\n",
            "Finished training of epoch 5/100 in 0.004s,\n",
            "         CE loss is 1.831289, training accuracy is 0.221, validation accuracy is 0.126\n",
            "         best train accuracy is 0.221, best validation accuracy is 0.126.\n",
            "Finished training of epoch 10/100 in 0.004s,\n",
            "         CE loss is 1.709802, training accuracy is 0.321, validation accuracy is 0.176\n",
            "         best train accuracy is 0.321, best validation accuracy is 0.176.\n",
            "Finished training of epoch 15/100 in 0.004s,\n",
            "         CE loss is 1.604005, training accuracy is 0.493, validation accuracy is 0.298\n",
            "         best train accuracy is 0.493, best validation accuracy is 0.298.\n",
            "Finished training of epoch 20/100 in 0.004s,\n",
            "         CE loss is 1.511066, training accuracy is 0.650, validation accuracy is 0.416\n",
            "         best train accuracy is 0.650, best validation accuracy is 0.416.\n",
            "Finished training of epoch 25/100 in 0.004s,\n",
            "         CE loss is 1.428886, training accuracy is 0.721, validation accuracy is 0.522\n",
            "         best train accuracy is 0.721, best validation accuracy is 0.522.\n",
            "Finished training of epoch 30/100 in 0.004s,\n",
            "         CE loss is 1.354760, training accuracy is 0.800, validation accuracy is 0.578\n",
            "         best train accuracy is 0.800, best validation accuracy is 0.578.\n",
            "Finished training of epoch 35/100 in 0.004s,\n",
            "         CE loss is 1.284576, training accuracy is 0.836, validation accuracy is 0.622\n",
            "         best train accuracy is 0.836, best validation accuracy is 0.622.\n",
            "Finished training of epoch 40/100 in 0.004s,\n",
            "         CE loss is 1.217275, training accuracy is 0.850, validation accuracy is 0.656\n",
            "         best train accuracy is 0.850, best validation accuracy is 0.656.\n",
            "Finished training of epoch 45/100 in 0.004s,\n",
            "         CE loss is 1.152222, training accuracy is 0.864, validation accuracy is 0.682\n",
            "         best train accuracy is 0.864, best validation accuracy is 0.682.\n",
            "Finished training of epoch 50/100 in 0.008s,\n",
            "         CE loss is 1.089026, training accuracy is 0.864, validation accuracy is 0.704\n",
            "         best train accuracy is 0.864, best validation accuracy is 0.704.\n",
            "Finished training of epoch 55/100 in 0.004s,\n",
            "         CE loss is 1.027874, training accuracy is 0.893, validation accuracy is 0.724\n",
            "         best train accuracy is 0.893, best validation accuracy is 0.724.\n",
            "Finished training of epoch 60/100 in 0.005s,\n",
            "         CE loss is 0.968969, training accuracy is 0.914, validation accuracy is 0.732\n",
            "         best train accuracy is 0.914, best validation accuracy is 0.732.\n",
            "Finished training of epoch 65/100 in 0.004s,\n",
            "         CE loss is 0.912499, training accuracy is 0.936, validation accuracy is 0.742\n",
            "         best train accuracy is 0.936, best validation accuracy is 0.742.\n",
            "Finished training of epoch 70/100 in 0.004s,\n",
            "         CE loss is 0.858615, training accuracy is 0.936, validation accuracy is 0.748\n",
            "         best train accuracy is 0.936, best validation accuracy is 0.748.\n",
            "Finished training of epoch 75/100 in 0.004s,\n",
            "         CE loss is 0.807473, training accuracy is 0.950, validation accuracy is 0.744\n",
            "         best train accuracy is 0.950, best validation accuracy is 0.748.\n",
            "Finished training of epoch 80/100 in 0.004s,\n",
            "         CE loss is 0.759199, training accuracy is 0.971, validation accuracy is 0.746\n",
            "         best train accuracy is 0.971, best validation accuracy is 0.748.\n",
            "Finished training of epoch 85/100 in 0.004s,\n",
            "         CE loss is 0.713849, training accuracy is 0.971, validation accuracy is 0.742\n",
            "         best train accuracy is 0.971, best validation accuracy is 0.748.\n",
            "Finished training of epoch 90/100 in 0.004s,\n",
            "         CE loss is 0.671405, training accuracy is 0.971, validation accuracy is 0.740\n",
            "         best train accuracy is 0.971, best validation accuracy is 0.748.\n",
            "Finished training of epoch 95/100 in 0.004s,\n",
            "         CE loss is 0.631791, training accuracy is 0.979, validation accuracy is 0.736\n",
            "         best train accuracy is 0.979, best validation accuracy is 0.748.\n"
          ]
        }
      ]
    }
  ]
}